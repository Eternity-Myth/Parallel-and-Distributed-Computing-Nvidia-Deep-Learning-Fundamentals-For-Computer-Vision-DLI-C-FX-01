{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/en-us/deep-learning-ai/education/\"> <img src=\"images/DLI Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *新しいデータ* を使った有効なモデルの作成\n",
    "\n",
    "ビッグ データ時代の現在、1 日に 250 京バイトものデータが生み出されています。\n",
    "[Kaggle.com](https://www.kaggle.com/datasets) や [UCI](https://archive.ics.uci.edu/ml/datasets.html) などのサイトでは無料のデータセットが提供されています。\n",
    "クラウドソーシングされたデータセットが、クリエイティブな手法で構築されています。\n",
    "たとえば、Facebook が写真に写っている友達への「タグ付け」をユーザーに依頼して作成した、ラベル付きの顔認識データセットなどがあります。\n",
    "また、専門家が手作業で生成した複雑なデータセットもあります。\n",
    "たとえば、レントゲン技師に心臓の特定の部分にラベルを付けるよう依頼して作成されたデータセットなどがあります。\n",
    "\n",
    "このコースではこれまで、16 枚の画像という *非常に小さな* データセットを使用してきました。\n",
    "本当に必要なのは数万枚のラベル付き画像ですが、(今のところ) Louie 用にはそれがありません。\n",
    "幸いなことに、Kaggle には犬と猫のラベル付き画像 18,750 枚で構成されるデータセットがあり、これを使用して始めることができます。\n",
    "ネットワークに Louie を教えるのではなく、犬とはどんなものであるかを教えるところから始めましょう。\n",
    "\n",
    "このタスクが終了すると、学習データセットに含まれていなかった犬と猫を正しく分類できる、学習済みのニューラルネットワークが完成します。\n",
    "\n",
    "はじめに、ラベル付きデータから学習データセットを *作成すること* で、DIGITS とディープラーニングのワークフローについてもう少し詳しく学びましょう。\n",
    "\n",
    "<a href=\"/digits/\">DIGITS を開く</a>\n",
    "\n",
    "### 最初のデータセットの読み込み\n",
    "\n",
    "DIGITS を開くと、ホーム画面が表示されます。\n",
    "ここで、新しいデータセットや新しいモデルを作成できます。\n",
    "\n",
    "まず、左の \"Datasets\" タブを選択します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/DIGITSdatasetHome.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前回のタスクの「Images of Beagles」データセットは (今は) 無視します。\n",
    "各画像がどの「カテゴリ」に属するのかをネットワークに判断させたいので、右の青い \"Images\" メニューから \"Classification\" を選択して、DIGITS に **新しい** 「分類」画像データセットを準備するよう指定します。\n",
    "\n",
    "このとき、ユーザー名の入力が必要な場合があります。\n",
    "要求されたら、小文字で任意の名前を入力してください。\n",
    "\n",
    "#### データの読み込みと構成\n",
    "\n",
    "\"Training Images\" フィールドに、以下のディレクトリを入力して、データが格納されているフォルダーを指定します。\n",
    "\n",
    "<pre>/dli/data/dogscats/train</pre>\n",
    "\n",
    "![](images/datasetttttings.PNG)\n",
    "\n",
    "ここでは、現在作業しているコンピューターではなく、学習環境内のフォルダーを指定する点に注意してください。\n",
    "この 2 つの間でデータをやり取りする方法は多数あります (日々更新されている「[Resources: Next Steps for Independent Deep Learning](https://docs.google.com/document/d/1A8r1Shh0ssiRzrxNcraK7PJ_NUFay--EX1aBovpVMKU/edit)」で説明しています)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データセットを読み込む前に、データの構造を把握するために、\"Training Images\" の横の「?」にマウスを合わせてみてください。\n",
    "\n",
    "*入力データと出力ラベルを対応付ける方法は多数あります。\n",
    "犬の画像が入った「dogs」フォルダーと、猫の画像が入った「cats」フォルダーを作成しました。\n",
    "この 2 つのフォルダーを「dogscats」という名前の別のフォルダーに入れました。\n",
    "DIGITS は、2 つのフォルダーがあることを認識し、2 つのカテゴリがあると判断しました。\n",
    "以上です。この後、皆さんはこれを自分のデータで練習します。*\n",
    "\n",
    "\"**% for validation**\" フィールドで 25% を割り当てたことに注目してください。\n",
    "これについては、データセットの読み込み中に確認しましょう。\n",
    "\n",
    "データセットの準備にかかる時間を短縮するために \"Encoding\" を \"PNG(lossless)\" から \"None\" に変更し、データセットに名前を付けます。\n",
    "\"Create\" を選択すると、約 3 分で学習用のデータが準備されます。\n",
    "準備の間、以下のセクションを読んで、何が行われるかを把握しましょう。\n",
    "\n",
    "![](images/datasetname1.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIGITS が行う処理\n",
    "\n",
    "指定したフォルダー内の画像を取得し、2 つの処理を行うよう、DIGITS に指示しました。\n",
    "\n",
    "1) 学習するネットワークで想定されているサイズに合うように、画像のサイズを標準化します。今回も AlexNet を学習します。AlexNet は 256x256 のカラー画像の入力を受け取るよう設計されています。これについては、次のタスクで詳しく説明します。\n",
    "\n",
    "2) 画像を 2 つのデータセットに分割します。カテゴリごとに 75% が学習用に使用され、25% が検証用に分離されます。\n",
    "\n",
    "学習データセットは、Louie 分類器を学習したときと同じように使用されます。\n",
    "つまり、 *ネットワーク上を画像が順伝播* し、出力が生成され、 *損失* が評価されます。\n",
    "この損失がネットワークを *逆伝播* し、重みが更新されます \n",
    "(ここでは詳しく説明しませんが、これがディープラーニングの要点です。 *コンピューターが実行する* 数学を理解していなくてもディープラーニングによる問題解決の障壁にはなりませんが、より詳しく学びたい場合は、[3Blue1Brown のこちらのビデオ](https://www.youtube.com/watch?v=Ilg3gGewQ5U) をダウンロードして、後でご覧ください)。\n",
    "\n",
    "![](images/propogation.png)\n",
    "\n",
    "### 検証データを使用したパフォーマンスの評価\n",
    "\n",
    "*新しいデータ* でのパフォーマンスの評価には検証データセットが使用されます。\n",
    "これには人間の学習では使用できないテクニックが使用されます。\n",
    "検証データをネットワークに入力すると出力が生成されますが、 *ネットワークは検証データからは何も学習しません* 。\n",
    "損失は報告されますが、モデル自体は変更されません。\n",
    "同じ検証データセットを使用しても、これらは常に新しいデータとして扱われるため、 *新しい* データでのパフォーマンスを何度でも評価することができます。\n",
    "\n",
    "![](images/forwardprop.png)\n",
    "\n",
    "いったんデータセットが読み込まれたのち、作成されたヒストグラムにマウスを合わせると、さらに詳細を確認することができます。\n",
    "\"Explore the db\" を選択すると、実際のデータを表示できます。\n",
    "\n",
    "これで DIGITS にデータを読み込む方法がわかりました。\n",
    "ネットワークの学習をどこで行う場合でも、同様の手順が必要です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習\n",
    "\n",
    "次の作業は、Louie データセットで行ったのと同じ方法で、ニューラルネットワークモデルを学習することです。\n",
    "\n",
    "左上の \"DIGITS\" を選択して DIGITS のホーム画面に移動します。\n",
    "次に、\"```New Model```\"、\"```Classification```\" の順に選択して、新しい分類モデルを作成します。\n",
    "これ以降の手順は、以下の内容が示すとおり、小さいデータセットで学習したときと同じです。\n",
    "\n",
    "<pre>先ほど読み込んだデータについて AlexNet の学習を 5 エポック行う。</pre> \n",
    "\n",
    "この作業を自力で行える場合は、以下の操作を行うことができます。\n",
    "\n",
    "<pre>読み込み済みのデータで画像分類ネットワークを学習する。</pre>\n",
    "\n",
    "復習が必要な場合は、前回のタスクの Notebook を参照してください: [Train a Model](../../task1/task/Train%20a%20Model-ja.ipynb)\n",
    "\n",
    "今回は、ネットワークの学習時に生成されるグラフをよく見てください。\n",
    "後ほど説明しますが、まずは結果を解釈してみましょう。\n",
    "主に、**学習中、グラフを使用してモデルの *パフォーマンス* を評価するにはどうすればよいか、について考えてみてください。**\n",
    "\n",
    "#### 注: 学習に 15 分以上かかる場合は、エポック (繰り返し回数) を 6 回以上に指定したと考えられます。\n",
    "\n",
    "画面の上部で \"Abort Job\" を選択し、\"Clone Job\" を選択して、手順を再度確認してください。\n",
    "\n",
    "学習が実行されている間、下のセクションを読んでください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推論\n",
    "\n",
    "モデルのジョブページに移動します。\n",
    "メインコースに戻ったときに、このページの内容を解釈する方法を詳しく説明しますが、ここではひとまず、これまでネットワークが見たことがない画像をテストして、成功したことを確認しましょう。\n",
    "\n",
    "*推論* は、学習したことに基づいて判断を下すプロセスです。\n",
    "学習済みモデルは、 **ラベルのない** 画像も分類できるようになっているはずです。\n",
    "\n",
    "![](images/trainingwithinferencevisualization.PNG)\n",
    "\n",
    "モデルウィンドウの下部で、単一の画像または画像リストをテストできます。\n",
    "左の \"Image Path\" テキストボックスに下記のパスを入力します。\n",
    "\n",
    "<pre>/dli/data/BeagleImages/louietest2.JPG</pre>\n",
    "\n",
    "\"**Classify One**\" ボタンを選択します。\n",
    "数秒後、新しいウィンドウが開き、画像と、画像の分類結果に関する情報が表示されます。\n",
    "\n",
    "![](images/TestLouieImage.PNG)\n",
    "\n",
    "この結果の解釈は 2 通りあります。\n",
    "\n",
    "1) 成功です。学習していないニューラルネットワークを選び、数千枚の *ラベル付き* 画像を見せました。これにより、統計的に有意な信頼度で、犬を犬として分類する出力が得られました。おめでとうございます。\n",
    "\n",
    "2) 失敗です。人間の学習者であれば、100% の信頼度で画像に犬が含まれていることを判断できるでしょう。ここで作成したモデルには、まだ大きな損失があります。\n",
    "\n",
    "2 つの解釈のどちらも間違っていませんが、今のところは 1 の解釈を採用して喜んでおきましょう。\n",
    "この Notebook を閉じたら、パフォーマンスについて詳しく見ていきます。\n",
    "\n",
    "### 他の画像でのテスト\n",
    "\n",
    "元のデータセット内の画像は、いずれもこの学習データセットには含まれませんでしたので、任意の画像をテストしてみてください。\n",
    "\n",
    "下のセルをクリックし、**Shift + Enter** を押すことで、画像のファイルパスを表示できます (これは、この後このコースでよく使用するテクニックです)。\n",
    "このフルファイルパスを \"Image Path\" フィールドに入力することでテストできます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!ls /dli/data/BeagleImages/Louie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このワークフローは、ほぼすべての画像分類タスクに使用できます。\n",
    "AlexNet を学習することで、ある人の画像から別の人の画像を分類したり、手書きの数字の画像から特定の数字の画像を分類したり、健康な患者と不健康な患者を分類したりできます。\n",
    "次のタスクで、これについて直接見ていきましょう。\n",
    "\n",
    "この最初のタスクは成功しましたが、まだ学ぶことは多数あります。\n",
    "\n",
    "コースに戻って、ここで行った作業に文脈を加えていきましょう。\n",
    "このウィンドウを閉じると、この GPU インスタンスを停止する \"Stop\" オプションが表示されます。\n",
    "このウィンドウを閉じたら、そのオプションを選択してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/en-us/deep-learning-ai/education/\"> <img src=\"images/DLI Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
