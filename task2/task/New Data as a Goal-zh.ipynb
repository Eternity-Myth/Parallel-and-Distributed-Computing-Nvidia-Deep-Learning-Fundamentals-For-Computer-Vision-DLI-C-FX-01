{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/en-us/deep-learning-ai/education/\"> <img src=\"images/DLI Header.png\" alt=\"标题\" style=\"width: 400px;\"/> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建对*新数据*有效的模型\n",
    "\n",
    "在大数据时代，我们每天约产生 250 亿亿字节数据。[Kaggle.com](https://www.kaggle.com/datasets) 和 [UCI](https://archive.ics.uci.edu/ml/datasets.html) 等类似平台可提供免费数据集。众包数据集通过创意方法构建而成，例如Facebook 让用户在照片中“标记”朋友以创建带标签的面部识别数据集。更复杂的数据集则由专家手动生成，例如让放射科医师标记心脏的特定部位。\n",
    "\n",
    "目前为止，我们一直所用的都是包含 16 张图像的*袖珍*数据集。我们实际上需要数万张已标记图像，但却（暂时）没有如此数量的 Louie 图像。幸运的是，Kaggle 提供的数据集包含 18750 张狗和猫的已标记图像，能够满足我们的需求。我们首先来教网络分辨什么是狗，而不是教它辨别谁是 Louie。\n",
    "\n",
    "这项任务结束后，您会获得经过训练的神经网络，该网络能够正确分类训练数据集之外的狗和猫。\n",
    " \n",
    "首先，请选择已标记数据*创建*训练数据集，以更多地了解 DIGITS 和深度学习工作流程。\n",
    "\n",
    "<a href=\"/digits/\">打开 DIGITS</a>\n",
    "\n",
    "### 加载第一个数据集\n",
    "\n",
    "启动 DIGITS 时，系统将转至创建新数据集或新模型的页面。\n",
    "\n",
    "首先，请选择左侧的“数据集”选项卡。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/DIGITSdatasetHome.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（暂时）忽略上次任务的 “比格犬图像” 数据集。我们希望网络能够判断每张图像所属的 “类别” ，因此从右侧蓝色 “图像” 菜单中选择 “Classification” （分类），以让 DIGITS 准备**新的**“分类” 图像数据集。\n",
    "\n",
    "此时，您可能需要输入用户名。如有要求，只需输入小写名称即可。\n",
    "\n",
    "#### 加载并组织数据\n",
    "\n",
    "在“Training Images”（训练图像）字段中输入以下目录，以将 DIGITS 指向存储数据的文件夹：\n",
    "\n",
    "<pre>/dli/data/dogscats/train</pre>\n",
    "\n",
    "![](images/datasetttttings.PNG)\n",
    "\n",
    "请注意，此处所指的文件夹位于训练环境中，而非您正操作的计算机。现有多种方法可支持在两者之间来回传递数据（重点介绍详见不断完善的 [资源：独立深度学习的后续规划](https://docs.google.com/document/d/1A8r1Shh0ssiRzrxNcraK7PJ_NUFay--EX1aBovpVMKU/edit)）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如要在加载数据集之前了解数据的构成方式，请将鼠标悬停在“训练图像”旁边的 ？ 上方。\n",
    "\n",
    "*现有许多方式可在输入数据与输出标签之间建立匹配。我们分别创建了包含狗和猫图像的文件夹，并将文件夹分别命名为 “dogs” （狗）和 “猫” （cats）。我们将这两个文件夹一同置于另一个文件夹中，并命名为 “猫狗” 。DIGITS 识别出了这两个文件夹，由此推断其中存在两个类别。稍后，您将使用自己的数据进行此练习。*\n",
    "\n",
    "请注意，我们在 “% for validation” 的文本框中填入25%，表明25%。您将在数据集加载时看到此值。\n",
    "\n",
    "如要缩短数据集的准备时间，请将“Encoding”（编码）从“PNG（无损）”更改为“None”（无），并为数据集命名。\n",
    "\n",
    "选择 “Create” （创建）后，DIGITS 需约 3 分钟时间来为您准备训练数据。在此期间，您可以阅读如下部分。\n",
    "\n",
    "![](images/datasetname1.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIGITS 的作用是什么？\n",
    "\n",
    "您已使用 DIGITS 提取指定文件夹中的图像，并执行以下两项操作：\n",
    "\n",
    "1) 以同等尺寸对图像进行标准化，使之与所训练网络期望的输入尺寸相匹配。我们将再次训练 AlexNet，其输入是 256X256 的彩色图像。\n",
    "\n",
    "2) 将图像集拆分成两个数据集，75%的数据集用于训练、25%用于验证。\n",
    "\n",
    "训练数据集的使用方式将与训练 Louie 分类器时所用方式相同；*通过网络前向传播图像*、生成输出、评估*损失*，通过网络*反向传播*返回损失以更新权重。（这是深度学习的核心过程，但此处不会详尽说明，因为对*计算机所执行*数学运算的理解不应是通过深度学习解决问题的阻碍。若您有意深究，可以保存 [3Blue1Brown 提供的这一视频] (https://www.youtube.com/watch?v=Ilg3gGewQ5U) 以便日后观看。）! [](images/propogation.png)\n",
    "\n",
    "### 使用验证数据评估性能\n",
    "\n",
    "验证数据集将用于评估模型对*新数据*的处理性能。验证数据通过网络生成输出，但网络*不会从此类数据中学习任何内容*。此过程只会输出验证损失，而模型本身不变！我们可以使用相同的验证数据集来反复评估模型在新数据上的表现。[](images/forwardprop.png)\n",
    "\n",
    "数据集加载完成后，您可以将鼠标悬停在“直方图”上方查看数据集详情，并选择“Explore the db”（探索数据库）来查看实际数据。\n",
    "\n",
    "您现已了解如何将数据加载至 DIGITS。无论您计划在何处训练网络，都需要遵循以下步骤。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练\n",
    "\n",
    "您的下一项工作是以与处理 Louie 数据集相同的方式训练神经网络模型。\n",
    "\n",
    "在屏幕左上角选择 “DIGITS” ，进入到DIGITS 主页面。接下来，请选择 ```New Model```（新模型）和 ```Classification```（分类）以创建新分类模型。之后的操作步骤均与在给定以下信息的情况下训练较小数据集时相同：\n",
    "\n",
    "<pre>使用刚加载的数据训练 “AlexNet” 网络，训练时长为5个周期。</pre> \n",
    "\n",
    "如果您可以独自完成上一步，接下来：\n",
    "\n",
    "<pre>使用预加载数据训练图像分类网络。</pre>\n",
    "\n",
    "如果您需要回顾先前内容，可以参考上次任务 [训练模型](../../task1/task/Train%20a%20Model.ipynb) 的 Notebook。\n",
    "\n",
    "在训练过程中，检查生成的图表，并尽可能理会图表中数值的含义，我们稍后将作讨论。关键问题：**您在训练模型时如何使用图表来评估其*性能*？**\n",
    "\n",
    "#### 注意：如果训练时间长于 15 分钟，您设置的训练周期数（迭代次数）可能超过了5。\n",
    "在屏幕顶部，您可以先 “中止作业” ，然后再 “克隆作业” 以查看上述说明。\n",
    "\n",
    "\n",
    "训练时，您可以阅读以下部分。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推理\n",
    "\n",
    "从您的模型作业页面。当返回主课程时，我们将深入剖析此页面内容的具体含义，但首先让我们测试一张网络从未见过的图像，以验证我们构建的网络是否成功。\n",
    "\n",
    "*推理*是基于所学内容做出判断的过程。我们所训练的模型应能具备以下能力：对**未标记**图像作出分类。\n",
    "\n",
    "![](images/trainingwithinferencevisualization.PNG)\n",
    "\n",
    "在模型窗口底部，您可以测试单张图像或一组图像。在左侧的 Image Path（图像路径）文本框中，键入路径 <pre>/dli/data/BeagleImages/louietest2.JPG</pre>。选择 **Classify One**（分类单张图像）按钮。几秒钟后，系统便会显示新窗口，窗口中会显示该图像以及模型试图对其进行分类的相关信息。\n",
    "\n",
    "![](images/TestLouieImage.PNG)\n",
    "\n",
    "您可按如下两种方式解释所产生的结果：\n",
    "\n",
    "1) 已成功分类！我们采用了未经训练的神经网络，并为其输入了数千张*已标记*图像，最后网络以经过数据统计的极高置信度将狗分类为狗。恭喜！\n",
    "\n",
    "2) 未成功分类。人类能100% 确信这张照片中包含一只狗。我们的模型仍存在重大性能缺陷。\n",
    "\n",
    "两者都正确，但我们目前已顺利实现第一种结果。在您关闭此 Notebook 后，我们还将检测模型性能。\n",
    "\n",
    "### 测试其他图像\n",
    "\n",
    "可以随意测试原始数据集中的任何图像，因为它们都不在此训练集中。\n",
    "\n",
    "单击下方单元并按下 **SHIFT 和 Enter**（您会在此课程余下部分经常用到此方法），即可看到图像的文件路径。之后，您可以在字段“Image Path”（图像路径）中输入完整文件路径进行测试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!ls /dli/data/BeagleImages/Louie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请注意，这一工作流程几乎适用于任何图像分类任务。您可以训练 AlexNet，以从以下图像中分类出您本人的图像：我的图像、他人的手写数字图像以及健康患者与不健康患者的图像等。我们将在下一任务中直接看到此信息。\n",
    "\n",
    "在顺利完成此项入门任务后，您还有更多内容需要学习。\n",
    "\n",
    "现在我们来返回课程，对刚刚完成的任务做一些总结。。关闭此窗口后，您将看到 “停止” 此 GPU 实例的选项。请在关闭此窗口后选中该选项。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/en-us/deep-learning-ai/education/\"> <img src=\"images/DLI Header.png\" alt=\"标题\" style=\"width: 400px;\"/> </a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
