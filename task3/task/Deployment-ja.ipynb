{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/en-us/deep-learning-ai/education/\"> <img src=\"images/DLI Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# デプロイ\n",
    "\n",
    "## 「モデル」を構成するファイル\n",
    "\n",
    "学習したネットワークを実際に利用できるように、学習環境から取り出して、アプリケーションに「デプロイ」しましょう。\n",
    "DIGITS を閉じたところから始めます。\n",
    "\n",
    "DIGITS によって、デプロイする必要があるファイルがディレクトリに保存されます。\n",
    "ファイルは、このディレクトリからダウンロードすることも、場所を指定することもできます。\n",
    "ここでは、学習したときと同じサーバーにモデルを展開するため、DIGITS が生成するフォルダーパスを指定します。\n",
    "\n",
    "### <a href=\"/digits\">DIGITS を開く</a>\n",
    "\n",
    "DIGITS のホームページから、「Dogs vs. Cats」と名付けたモデルを選択します。\n",
    "\n",
    "モデルの作成直後、学習中、および DIGITS の \"model\" タブでモデルを選択したときのいずれも、DIGITS ではモデルの「ジョブページ」が表示されます。\n",
    "このページの左上には \"Job Directory\" があります。\n",
    "\n",
    "![](images/ModelJobView.PNG)\n",
    "\n",
    "**ジョブディレクトリ (上でハイライトされた部分) をコピーし、下のコードブロック内の ##FIXME## を置き換えます。\n",
    "ディレクトリをコピーしたら、セルを実行し (Shift+Enter)、変数 <code>MODEL_JOB_DIR</code> にこれを格納します。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_JOB_DIR = '##FIXME##'  ## Remember to set this to be the job directory for your model\n",
    "!ls $MODEL_JOB_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "コピーと貼り付けが成功すると、そのディレクトリ内のすべてのファイルのリストが表示されます。\n",
    "以降の手順が表示内容に合わない場合は、コピー/貼り付けの手順を確認してください。\n",
    "\n",
    "今回も、モデルは、アーキテクチャ (訳注: ネットワークの構造) と重みの 2 つのファイルで構成されています。\n",
    "\n",
    "アーキテクチャは ```deploy.prototxt``` という名前のファイルです。\n",
    "重みは最新のスナップショットファイル ```snapshot_iter_#.caffemodel``` にあります。\n",
    "ここでは、スナップショット番号 735 に 5 回のエポックで学習された重みが含まれています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ARCHITECTURE = MODEL_JOB_DIR + '/' + 'deploy.prototxt'\n",
    "WEIGHTS = MODEL_JOB_DIR + '/' + 'snapshot_iter_735.caffemodel'\n",
    "print (\"Filepath to Architecture = \" + ARCHITECTURE)\n",
    "print(\"Filepath to weights = \"+ WEIGHTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、現在構築しているプログラムが、これらのファイルを確実に読み込み、処理できるようにする必要があります。\n",
    "この基本的なデプロイでは、フレームワークをインストール (またはインクルード) して、プログラムがモデルファイルを解釈できるようにする必要があります。\n",
    "フレームワークのインストールを必要としない環境のデプロイ方法については、このコースで後ほど学習します。\n",
    "並列処理を活用するために GPU を使用する必要もあります。\n",
    "先述のように、モデルは数十万の演算で構成されており、並列化によって大きく加速することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import caffe\n",
    "caffe.set_mode_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次は、「net」という名前の「Classifier」オブジェクトを作成しましょう。\n",
    "ワークフローが一般的であるほど、既存のツールでプロジェクトを作成するのが容易になります。\n",
    "このケースの画像分類は非常に一般的です。\n",
    "このため、次のコードブロックは、アーキテクチャファイルと重みファイル、およびデータに関する簡単な情報を受け取り、共通処理を容易に実行できるようにしています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize the Caffe model using the model trained in DIGITS\n",
    "net = caffe.Classifier(ARCHITECTURE, WEIGHTS,  \n",
    "                       channel_swap =(2, 1, 0), #Color images have three channels, Red, Green, and Blue.\n",
    "                       raw_scale=255) #Each pixel value is a number between 0 and 255\n",
    "                       #Each \"channel\" of our images are 256 x 256 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier クラスには、「predict」という名前のメソッドが含まれています。\n",
    "このメソッドは、上の定義にしたがって画像を入力として受け取り、その画像が各カテゴリに属する確率を出力します。\n",
    "\n",
    "## 期待する形式へ入力を変換: 前処理 (Preprocesing)\n",
    "\n",
    "簡単なものから始めるために、データセットからラベル付き画像を正しく分類してみましょう。\n",
    "以下のセルを実行することで、画像を読み込んで表示できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt #matplotlib.pyplot allows us to visualize results\n",
    "input_image= caffe.io.load_image('/dli/data/dogscats/train/cats/cat.10941.jpg')\n",
    "plt.imshow(input_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これがその画像ですが、ネットワークが想定している「入力」ではありません。\n",
    "\n",
    "推論用のデータを準備するには、以下の大原則に従います。\n",
    "\n",
    "<pre>学習の前に行ったことは、必ず推論の前にも行う。</pre>\n",
    "\n",
    "前のセクションで、DIGITS でモデルをトレーニングしたときに生成されたファイルを見ました。\n",
    "このセクションでは、DIGITS がデータセットを作成したときに生成されたファイルについて見ていきます。\n",
    "\n",
    "先ほど学習に使用した **データセット** のジョブディレクトリは、モデルページ「Dogs and Cats」からデータセットを選択するか、DIGITS の \"dataset\" タブでデータセットを選択すると表示されます。\n",
    "モデルのディレクトリと同じ場所にありますが、番号が異なります。\n",
    "\n",
    "![](images/datasetjobdir.PNG)\n",
    "\n",
    "このデータセットのジョブディレクトリで ##FIXME## を置き換えて下のコードを実行し、DATA_JOB_DIR を正しいファイルパスに設定して、内容を調べます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_JOB_DIR = '##FIXME##'  ## Remember to set this to be the job directory for your model\n",
    "!ls $DATA_JOB_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回も、ここには (現時点では) 必要以上の情報があります。\n",
    "データサイエンスやデータの準備について *学べること* は無限にありますが、それらはさまざまなディープラーニングの問題に対処していく中で明確になっていくでしょう。\n",
    "このケースでは、DIGITS が学習の前に 2 つの処理を実行しました。これを *前処理 (preprocessing)*といいます。\n",
    "\n",
    "1) DIGITS は、画像のサイズを 256x256 カラー画像に変更しました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "input_image=cv2.resize(input_image, (256, 256), 0,0)\n",
    "plt.imshow(input_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) DIGITS は、学習に必要な計算を減らすために、各画像から平均画像を減算することで画像を *正規化* しました。\n",
    "\n",
    "以下のようにして、平均画像を読み込み、テスト画像からこれを減算します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_image = caffe.io.load_image(DATA_JOB_DIR+'/mean.jpg')\n",
    "ready_image = input_image-mean_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データを元のままの状態で受け取り、ネットワークで想定されているデータに変換しました。\n",
    "次は、ネットワークが作成する出力の内容を見ていきましょう。\n",
    "\n",
    "## 順伝播: モデルの使用\n",
    "\n",
    "ここは重要なポイントです。関数を見てみましょう。\n",
    "\n",
    "<code>prediction = net.predict([grid_square])</code>\n",
    "\n",
    "他の[関数](https://www.khanacademy.org/computing/computer-programming/programming#functions)と同じように、<code>net.predict</code> は入力 <code>ready_image</code> を渡して、出力 <code>prediction</code> を返します。\n",
    "他の関数と違うのは、この関数は手順のリストに従わず、行列演算を層ごとに行って、画像を確率のベクトルに変換するという点です。\n",
    "\n",
    "以下のセルを実行すると、上のラベル付きデータからの予測が表示されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make prediction\n",
    "prediction = net.predict([ready_image])\n",
    "print prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "興味深いことに、それほど多くの情報は含まれていません。\n",
    "ネットワークは正規化された 256x256 のカラー画像を受け取り、長さ 2 のベクトルを生成しました。\n",
    "\n",
    "## 有用な出力の生成: 後処理 (Postprocessing)\n",
    "\n",
    "ここまで来れば、必要なものは何でも実際に作成できます。\n",
    "制約があるとすれば、それはプログラミング経験によるものです。\n",
    "創造力を発揮する前に、基本的なものを作成しましょう。\n",
    "このコードは、ネットワークが「猫」の確率より「犬」の確率として高い値を出力するかどうかを判定します。\n",
    "出力する場合は、シミュレーションした犬用のドアに犬が近付いたときにふさわしい画像が表示されます。\n",
    "出力しない場合は、ドアに猫がいると判断したときにふさわしい画像が表示されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Input image:\")\n",
    "plt.imshow(input_image)\n",
    "plt.show()\n",
    "\n",
    "print(\"Output:\")\n",
    "if prediction.argmax()==0:\n",
    "    print \"Sorry cat:( https://media.giphy.com/media/jb8aFEQk3tADS/giphy.gif\"\n",
    "else:\n",
    "    print \"Welcome dog! https://www.flickr.com/photos/aidras/5379402670\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これで、すべてが用意できました。\n",
    "犬だけを通すドアが観測するであろう画像をテストできます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Create an input our network expects\n",
    "input_image= caffe.io.load_image('/dli/data/fromnest.PNG')\n",
    "input_image=cv2.resize(input_image, (256, 256), 0,0)\n",
    "ready_image = input_image-mean_image\n",
    "##Treat our network as a function that takes an input and generates an output\n",
    "prediction = net.predict([ready_image])\n",
    "print(\"Input Image:\")\n",
    "plt.imshow(input_image)\n",
    "plt.show()\n",
    "print(prediction)\n",
    "##Create a useful output\n",
    "print(\"Output:\")\n",
    "if prediction.argmax()==0:\n",
    "    print \"Sorry cat:( https://media.giphy.com/media/jb8aFEQk3tADS/giphy.gif\"\n",
    "else:\n",
    "    print \"Welcome dog! https://www.flickr.com/photos/aidras/5379402670\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここで作成したのは、いわば、犬用ドアという課題のためのシミュレーターでした。\n",
    "カメラからの入力を受け取り、これをネットワークが想定しているデータに変換し、出力を生成、そしてその出力をユーザーにとって有用なものに変換するアプリケーションを作成しました。\n",
    "\n",
    "正の出力によって犬用ドアのモーターをコントロールするということも、簡単にできるでしょう。\n",
    "ディープラーニングに関して必要なものが、これで揃いました。\n",
    "上のコードブロックで試すことができる他の画像を確認するには、下のコマンドを実行して、テスト画像 (学習に使用されなかった画像) の <code>リスト</code> を表示します。\n",
    "これらの画像の一部では、間違った分類が出力されます。\n",
    "十分にテストしたらコースを進めて、パフォーマンスを向上する方法を学んでください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!ls /dli/data/dogscats/test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## すべてを統合する\n",
    "\n",
    "このデプロイプロセスを統合し、Jupyter Notebook の外からどう見えるか確認しましょう。\n",
    "[pythondeployment.py](../../../../edit/tasks/task3/task/pythondeployment.py) の Python ファイルには上と同じコードがありますが、1 つのファイルに統合されています。\n",
    "コース評価の最後にこの手法を使用するため、見ておいてください。\n",
    "テスト画像を可視化するには、ファイルパスを以下に追加してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TEST_IMAGE = '/dli/data/dogscats/test/1.jpg'\n",
    "display= caffe.io.load_image(TEST_IMAGE)\n",
    "plt.imshow(display)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、以下のようにして、その画像を入力とする小さい Python アプリケーションを実行します。\n",
    "出力の大半は無視して、下までスクロールします (エラーや警告も気にしないでください)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!python pythondeployment.py $TEST_IMAGE 2>/dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/en-us/deep-learning-ai/education/\"> <img src=\"images/DLI Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
