{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/en-us/deep-learning-ai/education/\"> <img src=\"images/DLI Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "raw_mimetype": "text/markdown"
   },
   "source": [
    "# 改进模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "您已学习了如何成功训练模型，下面我们就来努力将其改进为先进模型吧。在本实验中，我们将学习深度学习从业者在实现预期结果的过程中将会采用的几种途径。在课程期间，我们将对有助实现这些结果的技术抽丝剥茧、深入研究。\n",
    "\n",
    "现在，请返回我们的狗/猫分类器。\n",
    "\n",
    "## [从 DIGITS 主屏幕启动](/digits/)\n",
    "\n",
    "选择所创建的模型：“Dogs vs. Cats”（狗和猫）。\n",
    "\n",
    "除此之外，DIGITS 还将显示模型训练期间生成的图表。\n",
    "\n",
    "![](images/graphfromfirsttraining.png)\n",
    "\n",
    "图表中报告了三个指标：训练损失、验证损失和准确度。尽管或会出现波动，但训练损失值和验证损失值应会随训练次数的增加而逐渐减少。准确度能够衡量模型正确分类验证数据的性能。您将鼠标悬停在任何数据点上之后，便会看到其精确值。在本例中，最后一次训练的准确度约为 80%。由于初始网络为随机生成，因此您的结果可能略不同于此处所示结果。\n",
    "\n",
    "通过分析此图，我们可以发现：随着时间的推移，准确度在逐渐提高而损失则在逐渐减少。您可能会不禁发问：“如果我们延长训练时间，模型能否继续改进？”这是我们在实验中开展并讨论的第一次干预。\n",
    "\n",
    "## 延长学习\n",
    "\n",
    "正如听从父母和老师的建议一般，我们也让模型延长学习以提高准确度。\n",
    "\n",
    "一次**训练**是指对整个网络中的所有数据进行一次完整的学习。在本课程前期，我们通过一副抽认卡，并通过一次实验来比较一次训练。 “延长习”将需从模型上次中断的位置开始，执行更多次训练。\n",
    "\n",
    "如要访问该*状态*，请滚动至模型页面底部，并点击带标签的绿色大按钮“Make Pretrained Model”（构建预训练模型）。\n",
    "\n",
    "![](images/pretrainedbutton.PNG)\n",
    "\n",
    "此操作将会保存以下两项内容：\n",
    "\n",
    "1.您在选择“AlexNet”时所选定的“网络架构”。\n",
    "2.模型以参数形式“学习”的内容，且这些参数已在您的网络处理前 5 次训练中的数据时进行了调整。\n",
    "\n",
    "### 学习率\n",
    "\n",
    "除了模型的当前状态，我们还有必要了解其变化方式。查看一下训练图下方的图表：\n",
    "\n",
    "![](images/learningrate.png)\n",
    "\n",
    "您可能会有三个疑问：\n",
    "\n",
    "1) 什么是“学习率”？\n",
    "2) 学习率为何会在整个训练会话期间降低？\n",
    "3) 什么在控制学习率？\n",
    "\n",
    "1) 学习率是每个“权重”在训练期间的移动速率。每个权重都会朝着减少损失的方向移动，移动幅度为一个数值乘以学习率。\n",
    "2) 学习率在模型不断接近理想状态的训练过程中不断降低。开始训练时，网络对其所见内容*一无所知*。无论是狗还是其他，因为网络并不知道其会接收到图像数据、传感器数据还是其他数据。正因如此，网络才能习得大量的知识，以便到达理想的状态。经过数次训练后，权重会逐渐改善，因此有必要让网络对所收到的每张图像*减小反应度*。\n",
    "3) 您是学习率的控制者。学习率是我们设置训练时的众多 “超参数” 之一。我们稍后即会对其进行调整。理由如下：\n",
    "\n",
    "由于训练结束时学习率很低，所以当从预训练网络开始时，我们应以上次中断的位置为起点继续训练。下面，我们来为此预训练模型设置训练任务，并将初始学习率设为 0.0001。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 从预训练模型开始\n",
    "\n",
    "我们现可以此为起点创建新模型。选择左上角的“DIGITS”以返回 DIGITS 主屏幕，并仿照先前操作新创建一个图像分类模型。\n",
    "\n",
    "**新模型（图像）-> 分类**\n",
    "\n",
    "- 选择相同数据集 - （狗和猫）\n",
    "- 选择 3 和 8 之间的某个训练次数。（注意：在从头开始创建模型时，您还可在创建之初要求更多次训练。）\n",
    "- 将学习率改为 0.0001\n",
    "- 选择“advanced options”（高级选项）以“修正”该值下的学习率\n",
    "- 此时请不要选择“Standard Network”（标准网络），而要选“Pretrained Networks”（预训练网络）。\n",
    "- 选择刚创建的预训练模型：“Dogs vs. Cats”（狗和猫）。\n",
    "- 命名您的模型 - 我们选用“Study more”（加强学习）\n",
    "- 单击“Create”（创建）\n",
    "\n",
    "您的设置应如下所示：\n",
    "\n",
    "![](images/pretrainedmodelsetup.png)\n",
    "\n",
    "创建模型时，您将获得如下图形：\n",
    "\n",
    "![](images/pretrainedgraph.PNG)\n",
    "\n",
    "请注意以下事项：\n",
    "\n",
    "1.一如预期，准确度开始接近首个模型中断训练时的水平，即 80%。\n",
    "2.准确度“的确”在不断提高，这表明增加训练次数往往会提高性能。\n",
    "3.准确度的提高*速度*在减慢，这表明对同一数据开展更多次训练并非提高性能的唯一途径。\n",
    "\n",
    "您可以采取以下四种途径来提高性能。抽些时间来了解每种途径，最终将有助于提升您的模型性能。\n",
    "\n",
    "1) **数据**- 足够巨大且多样的数据集，其代表模型应处的工作环境。数据加工本身就是一种艺术形式。\n",
    "2) **超参数**- 更改学习率等类似选项就如同改变您的训练“风格”。寻找正确的超参数目前是一个通过试验来学习的手动过程。当您能够通过直觉判断出各种任务类型所适用的超参数时，您的模型性能便会提升。\n",
    "3) **训练时间**- 增加训练次数可在一定程度上提高性能。某些时候，训练过多会导致过拟合（人类也会如此），所以您不能将其作为唯一的干预手段。\n",
    "4) **网络架构**- 我们将在下一节开始试验网络架构。我们将此列为最后一种途径是想打破一个谬论，即人们必须掌握网络架构才能利用深度学习解决问题。这一领域令人着迷且影响巨大，而您若想提升技能，则需研读数学知识。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 部署获奖模型\n",
    "\n",
    "您此时不应部署自己刚已重新训练好的模型，而是要引入提高性能的捷径，即部署专业的预训练模型。\n",
    "\n",
    "在本节中，您将学习部署他人的网络，以便借助他人通过研究、计算和数据加工获得的性能提升。\n",
    "\n",
    "回顾课程可以发现，本课程开篇所述的特定深度学习工作流程是*图像分类*。我们首先执行这项任务的其中一个原因在于，该任务是深度学习要解决的最大挑战之一。研究社区已针对 [“ImageNet”](https://qz.com/1034972/the-data-that-changed-the-direction-of-ai-research-and-possibly-the-world/) 竞赛不断优化解决方案，而这些方案均为处理该任务提供了颇多助益。\n",
    "\n",
    "“ImageNet”是涵盖 1000 类普通图像的大型数据集。对此数据集取得最低损失的研究团队会赢得竞赛。我们当前训练的网络 AlexNet，曾在 2012 年赢得 Imagenet 冠军。从那以后，Google 和 Microsoft 的团队也曾获胜。\n",
    "\n",
    "这一点令人十分兴奋。我们不仅能够使用他们的网络架构，甚至还可使用其训练的权重，这些权重均可通过上述四种途径（即数据、超参数、训练时间和网络架构）获取。无需任何训练或收集任何数据，只需*部署*获奖的神经网络即可为您免去一切烦扰。\n",
    "\n",
    "在部署这些模型时，只需获取模型架构和权重即可。只需在 Google 中搜索“pretrained model alexnet imagenet caffe”（预训练模型 alexnet imagenet caffe），即可返回下载此模型的多个页面。\n",
    "\n",
    "我们将使用名为 wget 的工具进行下载。wget 是一种十分有效的方法，可以将网络数据直接下载至您工作的服务器，而无需先将其下载至本地计算机。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!wget http://dl.caffe.berkeleyvision.org/bvlc_alexnet.caffemodel\n",
    "!wget https://raw.githubusercontent.com/BVLC/caffe/master/models/bvlc_alexnet/deploy.prototxt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所下载文件正是我们在从头训练模型时由 DIGITS 生成的两个文件。我们从 DIGITS 中获取的另一个文件则是在训练过程中所用的均值图像。我们可以在下方下载这些文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!wget https://github.com/BVLC/caffe/blob/master/python/caffe/imagenet/ilsvrc_2012_mean.npy?raw=true\n",
    "!mv ilsvrc_2012_mean.npy?raw=true ilsvrc_2012_mean.npy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这些文件现都以如下格式存储在此服务器上：<pre>/dli/tasks/task4/task/deploy.prototxt</pre><pre>/dli/tasks/task4/task/bvlc_alexnet.caffemodel</pre><pre>/dli/tasks/task4/task/ilsvrc_2012_mean.npy</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面，我们将根据所学的相关部署知识，使用此模型来处理图像。首先，请启动模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import caffe\n",
    "import numpy as np\n",
    "caffe.set_mode_gpu\n",
    "import matplotlib.pyplot as plt #matplotlib.pyplot allows us to visualize results\n",
    "\n",
    "ARCHITECTURE = 'deploy.prototxt'\n",
    "WEIGHTS = 'bvlc_alexnet.caffemodel'\n",
    "MEAN_IMAGE = 'ilsvrc_2012_mean.npy'\n",
    "TEST_IMAGE = '/dli/data/BeagleImages/louietest2.JPG'\n",
    "\n",
    "# Initialize the Caffe model using the model trained in DIGITS\n",
    "net = caffe.Classifier(ARCHITECTURE, WEIGHTS) #Each \"channel\" of our images are 256 x 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，创建网络预计会接收到的输入。请注意，这不同于上个模型中所用的*预处理*。如要了解如何对 imagenet 进行预处理，请前往 [Caffe 网站](http://caffe.berkeleyvision.org/gathered/examples/imagenet.html) 查看相关说明文档："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load the image\n",
    "image= caffe.io.load_image(TEST_IMAGE)\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "#Load the mean image\n",
    "mean_image = np.load(MEAN_IMAGE)\n",
    "mu = mean_image.mean(1).mean(1)  # average over pixels to obtain the mean (BGR) pixel values\n",
    "\n",
    "# create transformer for the input called 'data'\n",
    "transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
    "transformer.set_transpose('data', (2,0,1))  # move image channels to outermost dimension\n",
    "transformer.set_mean('data', mu)            # subtract the dataset-mean value in each channel\n",
    "transformer.set_raw_scale('data', 255)      # rescale from [0, 1] to [0, 255]\n",
    "transformer.set_channel_swap('data', (2,1,0))  # swap channels from RGB to BGR\n",
    "# set the size of the input (we can skip this if we're happy with the default; we can also change it later, e.g., for different batch sizes)\n",
    "net.blobs['data'].reshape(1,        # batch size\n",
    "                          3,         # 3-channel (BGR) images\n",
    "                          227, 227)  # image size is 227x227\n",
    "\n",
    "transformed_image = transformer.preprocess('data', image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行函数并可视化输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# copy the image data into the memory allocated for the net\n",
    "net.blobs['data'].data[...] = transformed_image\n",
    "\n",
    "### perform classification\n",
    "output = net.forward()\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输出一个对用户有用的结果。\n",
    "\n",
    "以上显示的是一个数组，其包含所输入图像同属 1000 类图像中每一类的概率。让我们对其进行处理从而输出一个有用的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_prob = output['prob'][0]  # the output probability vector for the first image in the batch\n",
    "print 'predicted class is:', output_prob.argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "成功已近在咫尺。请在 [此处](https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a) 查看 imagenet 的各个类别，以便更清晰地了解编号所对应的内容。将此功能添加到我们的应用程序中，我们便能获得有用的端到端部署。\n",
    "\n",
    "再次使用 wget 以获取海量类别进行标记。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/HoldenCaulfieldRye/caffe/master/data/ilsvrc12/synset_words.txt\n",
    "labels_file = 'synset_words.txt'\n",
    "labels = np.loadtxt(labels_file, str, delimiter='\\t')\n",
    "\n",
    "print 'output label:', labels[output_prob.argmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如要清晰了解本应用程序的工作流程，请在此处查看应用程序的输入和输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print (\"Input image:\")\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "print(\"Output label:\" + labels[output_prob.argmax()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/en-us/deep-learning-ai/education/\"> <img src=\"images/DLI Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
