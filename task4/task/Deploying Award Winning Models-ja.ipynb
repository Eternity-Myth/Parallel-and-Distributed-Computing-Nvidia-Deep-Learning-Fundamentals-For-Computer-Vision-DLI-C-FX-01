{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mSfEAwmswI7c"
   },
   "source": [
    "# Deploying Other's Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5JHKuxZpwWoG"
   },
   "source": [
    "So far, you have learned to solve problems with deep learning by loading pre-organized data, choosing and training a network, and deploying the results into an application. As we begin our discussion of *performance*, we're going to start at the other end of the spectrum.\n",
    "\n",
    "Recall that deploying a trained model consists of:\n",
    "\n",
    "\n",
    "1.   Creating a \"Classifier\" object using the network's architecture and weights\n",
    "2.   Transforming the data you have into the data the model expects and the output the model generates into something useful\n",
    "\n",
    "In this section, you'll learn to deploy other people's networks so that you can get the performance gains of their research, compute time, and data curation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OwwR36O729jk"
   },
   "source": [
    "Recall that the specific deep learning workflow this course started with is *image classification.* One reason we start with this task is because it is one of the most solved challenges in Deep Learning. It has benefited from the research community refining solutions to a competition called [\"ImageNet.\"](https://qz.com/1034972/the-data-that-changed-the-direction-of-ai-research-and-possibly-the-world/)\n",
    "\n",
    "\"ImageNet\" is a large dataset with 1000 classes of common images. The competition granted awards for the research teams that had the lowest loss against this dataset. The network we have been working with, AlexNet, won Imagenet in 2012. Teams from Google and Microsoft have been winners since then. \n",
    "\n",
    "Here's the exciting part. Not only can we use their network architecture, we can even use their trained weights, acquired through the manipulation of the four levers above: data, hyperparameters, training time, and network architecture. Without any training or data collection, we can *deploy* award winning neural networks.\n",
    "\n",
    "All we need to deploy one of these models are the model's architecture and weights. A quick Google search for \"pretrained model alexnet imagenet caffe\" returns multiple pages to download this model.\n",
    "\n",
    "We'll download them both using a tool called wget. Wget is a great way of downloading data from the web directly to the server you're working on without pulling it to your local machine first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 208,
     "output_extras": [
      {
       "item_id": 22
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7437,
     "status": "ok",
     "timestamp": 1518824009438,
     "user": {
      "displayName": "Mike Mendelson",
      "photoUrl": "//lh3.googleusercontent.com/-qKdxHKiNjGw/AAAAAAAAAAI/AAAAAAAAFP0/AopRtAuuNb0/s50-c-k-no/photo.jpg",
      "userId": "100776263227808296548"
     },
     "user_tz": 480
    },
    "id": "hY_5cQAC9jSv",
    "outputId": "c9307535-b841-410c-bd86-0021193d4850"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-03-05 23:23:54--  http://dl.caffe.berkeleyvision.org/bvlc_alexnet.caffemodel\n",
      "Resolving dl.caffe.berkeleyvision.org (dl.caffe.berkeleyvision.org)... 169.229.222.251\n",
      "Connecting to dl.caffe.berkeleyvision.org (dl.caffe.berkeleyvision.org)|169.229.222.251|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 243862414 (233M) [application/octet-stream]\n",
      "Saving to: 'bvlc_alexnet.caffemodel.1'\n",
      "\n",
      "100%[======================================>] 243,862,414 25.0MB/s   in 9.8s   \n",
      "\n",
      "2018-03-05 23:24:04 (23.7 MB/s) - 'bvlc_alexnet.caffemodel.1' saved [243862414/243862414]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://dl.caffe.berkeleyvision.org/bvlc_alexnet.caffemodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 208,
     "output_extras": [
      {
       "item_id": 4
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2048,
     "status": "ok",
     "timestamp": 1518824043360,
     "user": {
      "displayName": "Mike Mendelson",
      "photoUrl": "//lh3.googleusercontent.com/-qKdxHKiNjGw/AAAAAAAAAAI/AAAAAAAAFP0/AopRtAuuNb0/s50-c-k-no/photo.jpg",
      "userId": "100776263227808296548"
     },
     "user_tz": 480
    },
    "id": "bYTpHJz39q9W",
    "outputId": "2f15f8d9-61ca-4084-f3a7-0f481ee5e680"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-03-05 23:28:18--  https://raw.githubusercontent.com/BVLC/caffe/master/models/bvlc_alexnet/deploy.prototxt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.32.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.32.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3629 (3.5K) [text/plain]\n",
      "Saving to: 'deploy.prototxt.2'\n",
      "\n",
      "100%[======================================>] 3,629       --.-K/s   in 0s      \n",
      "\n",
      "2018-03-05 23:28:18 (79.1 MB/s) - 'deploy.prototxt.2' saved [3629/3629]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/BVLC/caffe/master/models/bvlc_alexnet/deploy.prototxt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fs-BCAKu-Fta"
   },
   "source": [
    "Those are the same two files that DIGITS generated when we trained a model from scratch. The only other file we took from DIGITS was the mean image that was used during training. We can download that below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 208,
     "output_extras": [
      {
       "item_id": 3
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1669,
     "status": "ok",
     "timestamp": 1518824689318,
     "user": {
      "displayName": "Mike Mendelson",
      "photoUrl": "//lh3.googleusercontent.com/-qKdxHKiNjGw/AAAAAAAAAAI/AAAAAAAAFP0/AopRtAuuNb0/s50-c-k-no/photo.jpg",
      "userId": "100776263227808296548"
     },
     "user_tz": 480
    },
    "id": "wY7ozs6lAV2l",
    "outputId": "25f502d3-27d1-49d2-8a58-fca7d8e1dc23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-03-05 23:24:11--  https://github.com/BVLC/caffe/blob/master/python/caffe/imagenet/ilsvrc_2012_mean.npy\n",
      "Resolving github.com (github.com)... 192.30.253.112, 192.30.253.113\n",
      "Connecting to github.com (github.com)|192.30.253.112|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [text/html]\n",
      "Saving to: 'ilsvrc_2012_mean.npy.1'\n",
      "\n",
      "    [ <=>                                   ] 46,923      --.-K/s   in 0.004s  \n",
      "\n",
      "2018-03-05 23:24:11 (11.5 MB/s) - 'ilsvrc_2012_mean.npy.1' saved [46923]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/BVLC/caffe/blob/master/python/caffe/imagenet/ilsvrc_2012_mean.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1263,
     "status": "ok",
     "timestamp": 1518824693898,
     "user": {
      "displayName": "Mike Mendelson",
      "photoUrl": "//lh3.googleusercontent.com/-qKdxHKiNjGw/AAAAAAAAAAI/AAAAAAAAFP0/AopRtAuuNb0/s50-c-k-no/photo.jpg",
      "userId": "100776263227808296548"
     },
     "user_tz": 480
    },
    "id": "XgFh3TnZAXBb",
    "outputId": "340102a9-4c16-4931-ad29-ef14fb083d31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dli/tasks/task5/task\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rx6o_6DUAmPl"
   },
   "source": [
    "You now have the three files we need to repeat the workflow you learned in the previous section. We're going to write the code directly in python instead of in Jupyter, but take note that the steps are the same.\n",
    "\n",
    "Examine the code here and compare to what was written in the previous notebook:\n",
    "\n",
    "[deploying_imagenet_model.py](/dli/tasks/task5/task/deploying_imagenet_model.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = './deploy.prototxt.2'\n",
    "weights = './bvlc_alexnet.caffemodel'\n",
    "img = '/dli/tasks/task4/task/images/LouieReady.png'\n",
    "mean = './ilsvrc_2012_mean.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"AlexNet\"\r\n",
      "layer {\r\n",
      "  name: \"data\"\r\n",
      "  type: \"Input\"\r\n",
      "  top: \"data\"\r\n",
      "  input_param { shape: { dim: 10 dim: 3 dim: 227 dim: 227 } }\r\n",
      "}\r\n",
      "layer {\r\n",
      "  name: \"conv1\"\r\n",
      "  type: \"Convolution\"\r\n",
      "  bottom: \"data\"\r\n",
      "  top: \"conv1\"\r\n",
      "  param {\r\n",
      "    lr_mult: 1\r\n",
      "    decay_mult: 1\r\n",
      "  }\r\n",
      "  param {\r\n",
      "    lr_mult: 2\r\n",
      "    decay_mult: 0\r\n",
      "  }\r\n",
      "  convolution_param {\r\n",
      "    num_output: 96\r\n",
      "    kernel_size: 11\r\n",
      "    stride: 4\r\n",
      "  }\r\n",
      "}\r\n",
      "layer {\r\n",
      "  name: \"relu1\"\r\n",
      "  type: \"ReLU\"\r\n",
      "  bottom: \"conv1\"\r\n",
      "  top: \"conv1\"\r\n",
      "}\r\n",
      "layer {\r\n",
      "  name: \"norm1\"\r\n",
      "  type: \"LRN\"\r\n",
      "  bottom: \"conv1\"\r\n",
      "  top: \"norm1\"\r\n",
      "  lrn_param {\r\n",
      "    local_size: 5\r\n",
      "    alpha: 0.0001\r\n",
      "    beta: 0.75\r\n",
      "  }\r\n",
      "}\r\n",
      "layer {\r\n",
      "  name: \"pool1\"\r\n",
      "  type: \"Pooling\"\r\n",
      "  bottom: \"norm1\"\r\n",
      "  top: \"pool1\"\r\n",
      "  pooling_param {\r\n",
      "    pool: MAX\r\n",
      "    kernel_size: 3\r\n",
      "    stride: 2\r\n",
      "  }\r\n",
      "}\r\n",
      "layer {\r\n",
      "  name: \"conv2\"\r\n",
      "  type: \"Convolution\"\r\n",
      "  bottom: \"pool1\"\r\n",
      "  top: \"conv2\"\r\n",
      "  param {\r\n",
      "    lr_mult: 1\r\n",
      "    decay_mult: 1\r\n",
      "  }\r\n",
      "  param {\r\n",
      "    lr_mult: 2\r\n",
      "    decay_mult: 0\r\n",
      "  }\r\n",
      "  convolution_param {\r\n",
      "    num_output: 256\r\n",
      "    pad: 2\r\n",
      "    kernel_size: 5\r\n",
      "    group: 2\r\n",
      "  }\r\n",
      "}\r\n",
      "layer {\r\n",
      "  name: \"relu2\"\r\n",
      "  type: \"ReLU\"\r\n",
      "  bottom: \"conv2\"\r\n",
      "  top: \"conv2\"\r\n",
      "}\r\n",
      "layer {\r\n",
      "  name: \"norm2\"\r\n",
      "  type: \"LRN\"\r\n",
      "  bottom: \"conv2\"\r\n",
      "  top: \"norm2\"\r\n",
      "  lrn_param {\r\n",
      "    local_size: 5\r\n",
      "    alpha: 0.0001\r\n",
      "    beta: 0.75\r\n",
      "  }\r\n",
      "}\r\n",
      "layer {\r\n",
      "  name: \"pool2\"\r\n",
      "  type: \"Pooling\"\r\n",
      "  bottom: \"norm2\"\r\n",
      "  top: \"pool2\"\r\n",
      "  pooling_param {\r\n",
      "    pool: MAX\r\n",
      "    kernel_size: 3\r\n",
      "    stride: 2\r\n",
      "  }\r\n",
      "}\r\n",
      "layer {\r\n",
      "  name: \"conv3\"\r\n",
      "  type: \"Convolution\"\r\n",
      "  bottom: \"pool2\"\r\n",
      "  top: \"conv3\"\r\n",
      "  param {\r\n",
      "    lr_mult: 1\r\n",
      "    decay_mult: 1\r\n",
      "  }\r\n",
      "  param {\r\n",
      "    lr_mult: 2\r\n",
      "    decay_mult: 0\r\n",
      "  }\r\n",
      "  convolution_param {\r\n",
      "    num_output: 384\r\n",
      "    pad: 1\r\n",
      "    kernel_size: 3\r\n",
      "  }\r\n",
      "}\r\n",
      "layer {\r\n",
      "  name: \"relu3\"\r\n",
      "  type: \"ReLU\"\r\n",
      "  bottom: \"conv3\"\r\n",
      "  top: \"conv3\"\r\n",
      "}\r\n",
      "layer {\r\n",
      "  name: \"conv4\"\r\n",
      "  type: \"Convolution\"\r\n",
      "  bottom: \"conv3\"\r\n",
      "  top: \"conv4\"\r\n",
      "  param {\r\n",
      "    lr_mult: 1\r\n",
      "    decay_mult: 1\r\n",
      "  }\r\n",
      "  param {\r\n",
      "    lr_mult: 2\r\n",
      "    decay_mult: 0\r\n",
      "  }\r\n",
      "  convolution_param {\r\n",
      "    num_output: 384\r\n",
      "    pad: 1\r\n",
      "    kernel_size: 3\r\n",
      "    group: 2\r\n",
      "  }\r\n",
      "}\r\n",
      "layer {\r\n",
      "  name: \"relu4\"\r\n",
      "  type: \"ReLU\"\r\n",
      "  bottom: \"conv4\"\r\n",
      "  top: \"conv4\"\r\n",
      "}\r\n",
      "layer {\r\n",
      "  name: \"conv5\"\r\n",
      "  type: \"Convolution\"\r\n",
      "  bottom: \"conv4\"\r\n",
      "  top: \"conv5\"\r\n",
      "  param {\r\n",
      "    lr_mult: 1\r\n",
      "    decay_mult: 1\r\n",
      "  }\r\n",
      "  param {\r\n",
      "    lr_mult: 2\r\n",
      "    decay_mult: 0\r\n",
      "  }\r\n",
      "  convolution_param {\r\n",
      "    num_output: 256\r\n",
      "    pad: 1\r\n",
      "    kernel_size: 3\r\n",
      "    group: 2\r\n",
      "  }\r\n",
      "}\r\n",
      "layer {\r\n",
      "  name: \"relu5\"\r\n",
      "  type: \"ReLU\"\r\n",
      "  bottom: \"conv5\"\r\n",
      "  top: \"conv5\"\r\n",
      "}\r\n",
      "layer {\r\n",
      "  name: \"pool5\"\r\n",
      "  type: \"Pooling\"\r\n",
      "  bottom: \"conv5\"\r\n",
      "  top: \"pool5\"\r\n",
      "  pooling_param {\r\n",
      "    pool: MAX\r\n",
      "    kernel_size: 3\r\n",
      "    stride: 2\r\n",
      "  }\r\n",
      "}\r\n",
      "layer {\r\n",
      "  name: \"fc6\"\r\n",
      "  type: \"InnerProduct\"\r\n",
      "  bottom: \"pool5\"\r\n",
      "  top: \"fc6\"\r\n",
      "  param {\r\n",
      "    lr_mult: 1\r\n",
      "    decay_mult: 1\r\n",
      "  }\r\n",
      "  param {\r\n",
      "    lr_mult: 2\r\n",
      "    decay_mult: 0\r\n",
      "  }\r\n",
      "  inner_product_param {\r\n",
      "    num_output: 4096\r\n",
      "  }\r\n",
      "}\r\n",
      "layer {\r\n",
      "  name: \"relu6\"\r\n",
      "  type: \"ReLU\"\r\n",
      "  bottom: \"fc6\"\r\n",
      "  top: \"fc6\"\r\n",
      "}\r\n",
      "layer {\r\n",
      "  name: \"drop6\"\r\n",
      "  type: \"Dropout\"\r\n",
      "  bottom: \"fc6\"\r\n",
      "  top: \"fc6\"\r\n",
      "  dropout_param {\r\n",
      "    dropout_ratio: 0.5\r\n",
      "  }\r\n",
      "}\r\n",
      "layer {\r\n",
      "  name: \"fc7\"\r\n",
      "  type: \"InnerProduct\"\r\n",
      "  bottom: \"fc6\"\r\n",
      "  top: \"fc7\"\r\n",
      "  param {\r\n",
      "    lr_mult: 1\r\n",
      "    decay_mult: 1\r\n",
      "  }\r\n",
      "  param {\r\n",
      "    lr_mult: 2\r\n",
      "    decay_mult: 0\r\n",
      "  }\r\n",
      "  inner_product_param {\r\n",
      "    num_output: 4096\r\n",
      "  }\r\n",
      "}\r\n",
      "layer {\r\n",
      "  name: \"relu7\"\r\n",
      "  type: \"ReLU\"\r\n",
      "  bottom: \"fc7\"\r\n",
      "  top: \"fc7\"\r\n",
      "}\r\n",
      "layer {\r\n",
      "  name: \"drop7\"\r\n",
      "  type: \"Dropout\"\r\n",
      "  bottom: \"fc7\"\r\n",
      "  top: \"fc7\"\r\n",
      "  dropout_param {\r\n",
      "    dropout_ratio: 0.5\r\n",
      "  }\r\n",
      "}\r\n",
      "layer {\r\n",
      "  name: \"fc8\"\r\n",
      "  type: \"InnerProduct\"\r\n",
      "  bottom: \"fc7\"\r\n",
      "  top: \"fc8\"\r\n",
      "  param {\r\n",
      "    lr_mult: 1\r\n",
      "    decay_mult: 1\r\n",
      "  }\r\n",
      "  param {\r\n",
      "    lr_mult: 2\r\n",
      "    decay_mult: 0\r\n",
      "  }\r\n",
      "  inner_product_param {\r\n",
      "    num_output: 1000\r\n",
      "  }\r\n",
      "}\r\n",
      "layer {\r\n",
      "  name: \"prob\"\r\n",
      "  type: \"Softmax\"\r\n",
      "  bottom: \"fc8\"\r\n",
      "  top: \"prob\"\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!cat ./deploy.prototxt.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "libdc1394 error: Failed to initialize libdc1394\n",
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "I0305 23:28:35.014855   411 net.cpp:52] Initializing net from parameters: \n",
      "name: \"AlexNet\"\n",
      "state {\n",
      "  phase: TEST\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 10\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"conv2\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"conv3\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc8\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc8\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 1000\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"prob\"\n",
      "  type: \"Softmax\"\n",
      "  bottom: \"fc8\"\n",
      "  top: \"prob\"\n",
      "}\n",
      "I0305 23:28:35.016319   411 layer_factory.hpp:77] Creating layer data\n",
      "I0305 23:28:35.016350   411 net.cpp:94] Creating Layer data\n",
      "I0305 23:28:35.016366   411 net.cpp:409] data -> data\n",
      "I0305 23:28:35.017272   411 net.cpp:144] Setting up data\n",
      "I0305 23:28:35.017314   411 net.cpp:151] Top shape: 10 3 227 227 (1545870)\n",
      "I0305 23:28:35.017326   411 net.cpp:159] Memory required for data: 6183480\n",
      "I0305 23:28:35.017339   411 layer_factory.hpp:77] Creating layer conv1\n",
      "I0305 23:28:35.017360   411 net.cpp:94] Creating Layer conv1\n",
      "I0305 23:28:35.017372   411 net.cpp:435] conv1 <- data\n",
      "I0305 23:28:35.017387   411 net.cpp:409] conv1 -> conv1\n",
      "I0305 23:28:35.019209   411 net.cpp:144] Setting up conv1\n",
      "I0305 23:28:35.019246   411 net.cpp:151] Top shape: 10 96 55 55 (2904000)\n",
      "I0305 23:28:35.019258   411 net.cpp:159] Memory required for data: 17799480\n",
      "I0305 23:28:35.019284   411 layer_factory.hpp:77] Creating layer relu1\n",
      "I0305 23:28:35.019302   411 net.cpp:94] Creating Layer relu1\n",
      "I0305 23:28:35.019313   411 net.cpp:435] relu1 <- conv1\n",
      "I0305 23:28:35.019326   411 net.cpp:396] relu1 -> conv1 (in-place)\n",
      "I0305 23:28:35.019347   411 net.cpp:144] Setting up relu1\n",
      "I0305 23:28:35.019361   411 net.cpp:151] Top shape: 10 96 55 55 (2904000)\n",
      "I0305 23:28:35.019371   411 net.cpp:159] Memory required for data: 29415480\n",
      "I0305 23:28:35.019381   411 layer_factory.hpp:77] Creating layer norm1\n",
      "I0305 23:28:35.019399   411 net.cpp:94] Creating Layer norm1\n",
      "I0305 23:28:35.019409   411 net.cpp:435] norm1 <- conv1\n",
      "I0305 23:28:35.019423   411 net.cpp:409] norm1 -> norm1\n",
      "I0305 23:28:35.019481   411 net.cpp:144] Setting up norm1\n",
      "I0305 23:28:35.019497   411 net.cpp:151] Top shape: 10 96 55 55 (2904000)\n",
      "I0305 23:28:35.019507   411 net.cpp:159] Memory required for data: 41031480\n",
      "I0305 23:28:35.019518   411 layer_factory.hpp:77] Creating layer pool1\n",
      "I0305 23:28:35.019553   411 net.cpp:94] Creating Layer pool1\n",
      "I0305 23:28:35.019567   411 net.cpp:435] pool1 <- norm1\n",
      "I0305 23:28:35.019579   411 net.cpp:409] pool1 -> pool1\n",
      "I0305 23:28:35.019635   411 net.cpp:144] Setting up pool1\n",
      "I0305 23:28:35.019649   411 net.cpp:151] Top shape: 10 96 27 27 (699840)\n",
      "I0305 23:28:35.019660   411 net.cpp:159] Memory required for data: 43830840\n",
      "I0305 23:28:35.019670   411 layer_factory.hpp:77] Creating layer conv2\n",
      "I0305 23:28:35.019685   411 net.cpp:94] Creating Layer conv2\n",
      "I0305 23:28:35.019696   411 net.cpp:435] conv2 <- pool1\n",
      "I0305 23:28:35.019709   411 net.cpp:409] conv2 -> conv2\n",
      "I0305 23:28:35.021749   411 net.cpp:144] Setting up conv2\n",
      "I0305 23:28:35.021787   411 net.cpp:151] Top shape: 10 256 27 27 (1866240)\n",
      "I0305 23:28:35.021800   411 net.cpp:159] Memory required for data: 51295800\n",
      "I0305 23:28:35.021818   411 layer_factory.hpp:77] Creating layer relu2\n",
      "I0305 23:28:35.021832   411 net.cpp:94] Creating Layer relu2\n",
      "I0305 23:28:35.021843   411 net.cpp:435] relu2 <- conv2\n",
      "I0305 23:28:35.021859   411 net.cpp:396] relu2 -> conv2 (in-place)\n",
      "I0305 23:28:35.021877   411 net.cpp:144] Setting up relu2\n",
      "I0305 23:28:35.021889   411 net.cpp:151] Top shape: 10 256 27 27 (1866240)\n",
      "I0305 23:28:35.021899   411 net.cpp:159] Memory required for data: 58760760\n",
      "I0305 23:28:35.021910   411 layer_factory.hpp:77] Creating layer norm2\n",
      "I0305 23:28:35.021924   411 net.cpp:94] Creating Layer norm2\n",
      "I0305 23:28:35.021934   411 net.cpp:435] norm2 <- conv2\n",
      "I0305 23:28:35.021948   411 net.cpp:409] norm2 -> norm2\n",
      "I0305 23:28:35.022009   411 net.cpp:144] Setting up norm2\n",
      "I0305 23:28:35.022024   411 net.cpp:151] Top shape: 10 256 27 27 (1866240)\n",
      "I0305 23:28:35.022035   411 net.cpp:159] Memory required for data: 66225720\n",
      "I0305 23:28:35.022045   411 layer_factory.hpp:77] Creating layer pool2\n",
      "I0305 23:28:35.022060   411 net.cpp:94] Creating Layer pool2\n",
      "I0305 23:28:35.022070   411 net.cpp:435] pool2 <- norm2\n",
      "I0305 23:28:35.022085   411 net.cpp:409] pool2 -> pool2\n",
      "I0305 23:28:35.022135   411 net.cpp:144] Setting up pool2\n",
      "I0305 23:28:35.022150   411 net.cpp:151] Top shape: 10 256 13 13 (432640)\n",
      "I0305 23:28:35.022161   411 net.cpp:159] Memory required for data: 67956280\n",
      "I0305 23:28:35.022171   411 layer_factory.hpp:77] Creating layer conv3\n",
      "I0305 23:28:35.022189   411 net.cpp:94] Creating Layer conv3\n",
      "I0305 23:28:35.022200   411 net.cpp:435] conv3 <- pool2\n",
      "I0305 23:28:35.022213   411 net.cpp:409] conv3 -> conv3\n",
      "I0305 23:28:35.024977   411 net.cpp:144] Setting up conv3\n",
      "I0305 23:28:35.025012   411 net.cpp:151] Top shape: 10 384 13 13 (648960)\n",
      "I0305 23:28:35.025024   411 net.cpp:159] Memory required for data: 70552120\n",
      "I0305 23:28:35.025043   411 layer_factory.hpp:77] Creating layer relu3\n",
      "I0305 23:28:35.025060   411 net.cpp:94] Creating Layer relu3\n",
      "I0305 23:28:35.025072   411 net.cpp:435] relu3 <- conv3\n",
      "I0305 23:28:35.025085   411 net.cpp:396] relu3 -> conv3 (in-place)\n",
      "I0305 23:28:35.025101   411 net.cpp:144] Setting up relu3\n",
      "I0305 23:28:35.025115   411 net.cpp:151] Top shape: 10 384 13 13 (648960)\n",
      "I0305 23:28:35.025125   411 net.cpp:159] Memory required for data: 73147960\n",
      "I0305 23:28:35.025135   411 layer_factory.hpp:77] Creating layer conv4\n",
      "I0305 23:28:35.025152   411 net.cpp:94] Creating Layer conv4\n",
      "I0305 23:28:35.025162   411 net.cpp:435] conv4 <- conv3\n",
      "I0305 23:28:35.025179   411 net.cpp:409] conv4 -> conv4\n",
      "I0305 23:28:35.027369   411 net.cpp:144] Setting up conv4\n",
      "I0305 23:28:35.027403   411 net.cpp:151] Top shape: 10 384 13 13 (648960)\n",
      "I0305 23:28:35.027415   411 net.cpp:159] Memory required for data: 75743800\n",
      "I0305 23:28:35.027431   411 layer_factory.hpp:77] Creating layer relu4\n",
      "I0305 23:28:35.027444   411 net.cpp:94] Creating Layer relu4\n",
      "I0305 23:28:35.027456   411 net.cpp:435] relu4 <- conv4\n",
      "I0305 23:28:35.027472   411 net.cpp:396] relu4 -> conv4 (in-place)\n",
      "I0305 23:28:35.027487   411 net.cpp:144] Setting up relu4\n",
      "I0305 23:28:35.027500   411 net.cpp:151] Top shape: 10 384 13 13 (648960)\n",
      "I0305 23:28:35.027510   411 net.cpp:159] Memory required for data: 78339640\n",
      "I0305 23:28:35.027520   411 layer_factory.hpp:77] Creating layer conv5\n",
      "I0305 23:28:35.027561   411 net.cpp:94] Creating Layer conv5\n",
      "I0305 23:28:35.027575   411 net.cpp:435] conv5 <- conv4\n",
      "I0305 23:28:35.027598   411 net.cpp:409] conv5 -> conv5\n",
      "I0305 23:28:35.029238   411 net.cpp:144] Setting up conv5\n",
      "I0305 23:28:35.029273   411 net.cpp:151] Top shape: 10 256 13 13 (432640)\n",
      "I0305 23:28:35.029285   411 net.cpp:159] Memory required for data: 80070200\n",
      "I0305 23:28:35.029307   411 layer_factory.hpp:77] Creating layer relu5\n",
      "I0305 23:28:35.029322   411 net.cpp:94] Creating Layer relu5\n",
      "I0305 23:28:35.029333   411 net.cpp:435] relu5 <- conv5\n",
      "I0305 23:28:35.029345   411 net.cpp:396] relu5 -> conv5 (in-place)\n",
      "I0305 23:28:35.029361   411 net.cpp:144] Setting up relu5\n",
      "I0305 23:28:35.029373   411 net.cpp:151] Top shape: 10 256 13 13 (432640)\n",
      "I0305 23:28:35.029384   411 net.cpp:159] Memory required for data: 81800760\n",
      "I0305 23:28:35.029394   411 layer_factory.hpp:77] Creating layer pool5\n",
      "I0305 23:28:35.029410   411 net.cpp:94] Creating Layer pool5\n",
      "I0305 23:28:35.029420   411 net.cpp:435] pool5 <- conv5\n",
      "I0305 23:28:35.029433   411 net.cpp:409] pool5 -> pool5\n",
      "I0305 23:28:35.029490   411 net.cpp:144] Setting up pool5\n",
      "I0305 23:28:35.029506   411 net.cpp:151] Top shape: 10 256 6 6 (92160)\n",
      "I0305 23:28:35.029517   411 net.cpp:159] Memory required for data: 82169400\n",
      "I0305 23:28:35.029527   411 layer_factory.hpp:77] Creating layer fc6\n",
      "I0305 23:28:35.029549   411 net.cpp:94] Creating Layer fc6\n",
      "I0305 23:28:35.029561   411 net.cpp:435] fc6 <- pool5\n",
      "I0305 23:28:35.029572   411 net.cpp:409] fc6 -> fc6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0305 23:28:35.146833   411 net.cpp:144] Setting up fc6\n",
      "I0305 23:28:35.146912   411 net.cpp:151] Top shape: 10 4096 (40960)\n",
      "I0305 23:28:35.146924   411 net.cpp:159] Memory required for data: 82333240\n",
      "I0305 23:28:35.146948   411 layer_factory.hpp:77] Creating layer relu6\n",
      "I0305 23:28:35.146970   411 net.cpp:94] Creating Layer relu6\n",
      "I0305 23:28:35.146983   411 net.cpp:435] relu6 <- fc6\n",
      "I0305 23:28:35.146998   411 net.cpp:396] relu6 -> fc6 (in-place)\n",
      "I0305 23:28:35.147022   411 net.cpp:144] Setting up relu6\n",
      "I0305 23:28:35.147035   411 net.cpp:151] Top shape: 10 4096 (40960)\n",
      "I0305 23:28:35.147045   411 net.cpp:159] Memory required for data: 82497080\n",
      "I0305 23:28:35.147056   411 layer_factory.hpp:77] Creating layer drop6\n",
      "I0305 23:28:35.147078   411 net.cpp:94] Creating Layer drop6\n",
      "I0305 23:28:35.147089   411 net.cpp:435] drop6 <- fc6\n",
      "I0305 23:28:35.147106   411 net.cpp:396] drop6 -> fc6 (in-place)\n",
      "I0305 23:28:35.147147   411 net.cpp:144] Setting up drop6\n",
      "I0305 23:28:35.147162   411 net.cpp:151] Top shape: 10 4096 (40960)\n",
      "I0305 23:28:35.147172   411 net.cpp:159] Memory required for data: 82660920\n",
      "I0305 23:28:35.147182   411 layer_factory.hpp:77] Creating layer fc7\n",
      "I0305 23:28:35.147198   411 net.cpp:94] Creating Layer fc7\n",
      "I0305 23:28:35.147210   411 net.cpp:435] fc7 <- fc6\n",
      "I0305 23:28:35.147228   411 net.cpp:409] fc7 -> fc7\n",
      "I0305 23:28:35.199728   411 net.cpp:144] Setting up fc7\n",
      "I0305 23:28:35.199802   411 net.cpp:151] Top shape: 10 4096 (40960)\n",
      "I0305 23:28:35.199815   411 net.cpp:159] Memory required for data: 82824760\n",
      "I0305 23:28:35.199837   411 layer_factory.hpp:77] Creating layer relu7\n",
      "I0305 23:28:35.199861   411 net.cpp:94] Creating Layer relu7\n",
      "I0305 23:28:35.199873   411 net.cpp:435] relu7 <- fc7\n",
      "I0305 23:28:35.199888   411 net.cpp:396] relu7 -> fc7 (in-place)\n",
      "I0305 23:28:35.199913   411 net.cpp:144] Setting up relu7\n",
      "I0305 23:28:35.199925   411 net.cpp:151] Top shape: 10 4096 (40960)\n",
      "I0305 23:28:35.199936   411 net.cpp:159] Memory required for data: 82988600\n",
      "I0305 23:28:35.199946   411 layer_factory.hpp:77] Creating layer drop7\n",
      "I0305 23:28:35.199961   411 net.cpp:94] Creating Layer drop7\n",
      "I0305 23:28:35.199971   411 net.cpp:435] drop7 <- fc7\n",
      "I0305 23:28:35.199986   411 net.cpp:396] drop7 -> fc7 (in-place)\n",
      "I0305 23:28:35.200026   411 net.cpp:144] Setting up drop7\n",
      "I0305 23:28:35.200042   411 net.cpp:151] Top shape: 10 4096 (40960)\n",
      "I0305 23:28:35.200053   411 net.cpp:159] Memory required for data: 83152440\n",
      "I0305 23:28:35.200063   411 layer_factory.hpp:77] Creating layer fc8\n",
      "I0305 23:28:35.200079   411 net.cpp:94] Creating Layer fc8\n",
      "I0305 23:28:35.200089   411 net.cpp:435] fc8 <- fc7\n",
      "I0305 23:28:35.200104   411 net.cpp:409] fc8 -> fc8\n",
      "I0305 23:28:35.211181   411 net.cpp:144] Setting up fc8\n",
      "I0305 23:28:35.211216   411 net.cpp:151] Top shape: 10 1000 (10000)\n",
      "I0305 23:28:35.211228   411 net.cpp:159] Memory required for data: 83192440\n",
      "I0305 23:28:35.211244   411 layer_factory.hpp:77] Creating layer prob\n",
      "I0305 23:28:35.211261   411 net.cpp:94] Creating Layer prob\n",
      "I0305 23:28:35.211272   411 net.cpp:435] prob <- fc8\n",
      "I0305 23:28:35.211287   411 net.cpp:409] prob -> prob\n",
      "I0305 23:28:35.211390   411 net.cpp:144] Setting up prob\n",
      "I0305 23:28:35.211405   411 net.cpp:151] Top shape: 10 1000 (10000)\n",
      "I0305 23:28:35.211414   411 net.cpp:159] Memory required for data: 83232440\n",
      "I0305 23:28:35.211426   411 net.cpp:222] prob does not need backward computation.\n",
      "I0305 23:28:35.211436   411 net.cpp:222] fc8 does not need backward computation.\n",
      "I0305 23:28:35.211447   411 net.cpp:222] drop7 does not need backward computation.\n",
      "I0305 23:28:35.211457   411 net.cpp:222] relu7 does not need backward computation.\n",
      "I0305 23:28:35.211468   411 net.cpp:222] fc7 does not need backward computation.\n",
      "I0305 23:28:35.211478   411 net.cpp:222] drop6 does not need backward computation.\n",
      "I0305 23:28:35.211489   411 net.cpp:222] relu6 does not need backward computation.\n",
      "I0305 23:28:35.211499   411 net.cpp:222] fc6 does not need backward computation.\n",
      "I0305 23:28:35.211510   411 net.cpp:222] pool5 does not need backward computation.\n",
      "I0305 23:28:35.211521   411 net.cpp:222] relu5 does not need backward computation.\n",
      "I0305 23:28:35.211531   411 net.cpp:222] conv5 does not need backward computation.\n",
      "I0305 23:28:35.211562   411 net.cpp:222] relu4 does not need backward computation.\n",
      "I0305 23:28:35.211573   411 net.cpp:222] conv4 does not need backward computation.\n",
      "I0305 23:28:35.211583   411 net.cpp:222] relu3 does not need backward computation.\n",
      "I0305 23:28:35.211593   411 net.cpp:222] conv3 does not need backward computation.\n",
      "I0305 23:28:35.211606   411 net.cpp:222] pool2 does not need backward computation.\n",
      "I0305 23:28:35.211616   411 net.cpp:222] norm2 does not need backward computation.\n",
      "I0305 23:28:35.211627   411 net.cpp:222] relu2 does not need backward computation.\n",
      "I0305 23:28:35.211637   411 net.cpp:222] conv2 does not need backward computation.\n",
      "I0305 23:28:35.211647   411 net.cpp:222] pool1 does not need backward computation.\n",
      "I0305 23:28:35.211658   411 net.cpp:222] norm1 does not need backward computation.\n",
      "I0305 23:28:35.211669   411 net.cpp:222] relu1 does not need backward computation.\n",
      "I0305 23:28:35.211680   411 net.cpp:222] conv1 does not need backward computation.\n",
      "I0305 23:28:35.211691   411 net.cpp:222] data does not need backward computation.\n",
      "I0305 23:28:35.211702   411 net.cpp:264] This network produces output prob\n",
      "I0305 23:28:35.211732   411 net.cpp:284] Network initialization done.\n",
      "I0305 23:28:35.378911   411 upgrade_proto.cpp:43] Attempting to upgrade input file specified using deprecated transformation parameters: ./bvlc_alexnet.caffemodel\n",
      "I0305 23:28:35.378976   411 upgrade_proto.cpp:46] Successfully upgraded file specified using deprecated data transformation parameters.\n",
      "W0305 23:28:35.378990   411 upgrade_proto.cpp:48] Note that future Caffe releases will only support transform_param messages for transformation fields.\n",
      "I0305 23:28:35.379000   411 upgrade_proto.cpp:52] Attempting to upgrade input file specified using deprecated V1LayerParameter: ./bvlc_alexnet.caffemodel\n",
      "I0305 23:28:35.645088   411 upgrade_proto.cpp:60] Successfully upgraded file specified using deprecated V1LayerParameter\n",
      "I0305 23:28:35.698385   411 net.cpp:791] Ignoring source layer loss\n",
      "Traceback (most recent call last):\n",
      "  File \"/dli/tasks/task5/task/deploying_imagenet_model.py\", line 21, in <module>\n",
      "    mean_image = caffe.io.load_image(MEAN_IMAGE)\n",
      "  File \"/usr/local/python/caffe/io.py\", line 296, in load_image\n",
      "    img = skimage.img_as_float(skimage.io.imread(filename, as_grey=not color)).astype(np.float32)\n",
      "  File \"/usr/lib/python2.7/dist-packages/skimage/io/_io.py\", line 150, in imread\n",
      "    img = call_plugin('imread', fname, plugin=plugin, **plugin_args)\n",
      "  File \"/usr/lib/python2.7/dist-packages/skimage/io/_plugins/plugin.py\", line 105, in call\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/lib/python2.7/dist-packages/skimage/io/_plugins/pil_plugin.py\", line 21, in imread\n",
      "    im = Image.open(fname)\n",
      "  File \"/usr/lib/python2.7/dist-packages/PIL/Image.py\", line 2028, in open\n",
      "    raise IOError(\"cannot identify image file\")\n",
      "IOError: cannot identify image file\n"
     ]
    }
   ],
   "source": [
    "!python /dli/tasks/task5/task/deploying_imagenet_model.py $arch $weights $img $mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how we've created a general program for classification where the variables are the architecture, weights, and mean image. We can now classify images by finding these files for any model that anyone else has trained. Go ahead and see what else you can find to deploy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, how can we use this to solve our challenge of a dog/cat classifier?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "Untitled1.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
